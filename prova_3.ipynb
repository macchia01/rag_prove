{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "# Load the document\n",
    "loader = PyPDFLoader(\"Foundations of LLMs.pdf\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Split the document into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=30, separator=\"\\n\")\n",
    "docs = text_splitter.split_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# âœ… Impostiamo il modello per funzionare sulla CPU\n",
    "embedding_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {\"device\": \"cpu\"}  # ðŸ”´ Cambia \"cuda\" in \"cpu\"\n",
    "\n",
    "# âœ… Caricamento del modello\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_name,\n",
    "    model_kwargs=model_kwargs\n",
    ")\n",
    "\n",
    "# âœ… Creazione dello store vettoriale FAISS\n",
    "vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# âœ… Salvataggio e caricamento dello store vettoriale\n",
    "vectorstore.save_local(\"faiss_index_\")\n",
    "persisted_vectorstore = FAISS.load_local(\"faiss_index_\", embeddings, allow_dangerous_deserialization=True)\n",
    "\n",
    "# âœ… Creazione del retriever\n",
    "retriever = persisted_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "What do you call a fake noodle?\n",
      "\n",
      "An impasta.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "# Initialize the LLaMA model\n",
    "llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Test with a sample prompt\n",
    "response = llm.invoke(\"Tell me a joke\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'What is long sequence modeling?', 'result': 'Long sequence modeling refers to the process of analyzing or generating sequences that are significantly longer than what can be accommodated by traditional models. In the context of language models, this often involves dealing with very large input sequences, such as text documents or conversations, where each token represents a word or character in the sequence.'}\n",
      "{'query': 'what is model ensembling?', 'result': 'According to the context provided, Model Ensembling (option a) refers to a method where multiple LLMs varying in architectures or parameters are used. Each LLM receives the same prompt and produces a prediction, which are then combined to generate the final prediction.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# âœ… Crea il modello di QA con il retriever\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever)\n",
    "\n",
    "# âœ… Loop interattivo per interrogare il sistema\n",
    "while True:\n",
    "    query = input(\"Type your query (or type 'Exit' to quit): \\n\")\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "    \n",
    "    # ðŸ”´ Sostituire .run() con .invoke()\n",
    "    result = qa.invoke(query)  # âœ… Metodo corretto\n",
    "    print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag_prove)",
   "language": "python",
   "name": "rag_prove"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
